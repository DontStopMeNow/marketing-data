{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a92c156537d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabspath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from os.path import abspath\n",
    "from typing import Dict, Any\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import learning_curve, GridSearchCV\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost\n",
    "import lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = abspath(\"./data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(source, sep=\";\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вернём значения\n",
    "Напишем мапперы значений, которые авторы датасета закодировали. Все числовые отрезки заменим на число из этого отрезка, чаще всего середину."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Less than $10,000\n",
    "2. $10,000 to $14,999\n",
    "3. $15,000 to $19,999\n",
    "4. $20,000 to $24,999\n",
    "5. $25,000 to $29,999\n",
    "6. $30,000 to $39,999\n",
    "7. $40,000 to $49,999\n",
    "8. $50,000 to $74,999\n",
    "9. $75,000 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_income_map = {\n",
    "    1: 7500.,\n",
    "    2: 12500.,\n",
    "    3: 17500.,\n",
    "    4: 22500.,\n",
    "    5: 27500.,\n",
    "    6: 35000.,\n",
    "    7: 45000.,\n",
    "    8: 60000.,\n",
    "    9: 90000.\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Male\n",
    "2. Female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_sex_map = {\n",
    "    1: \"m\",\n",
    "    2: \"f\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " 1. Married\n",
    " 2. Living together, not married\n",
    " 3. Divorced or separated\n",
    " 4. Widowed\n",
    " 5. Single, never married"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decode_marital_status_map = {\n",
    "    1: \"Married\",\n",
    "    2: \"Living together, not married\",\n",
    "    3: \"Divorced or separated\",\n",
    "    4: \"Widowed\",\n",
    "    5: \"Single, never married\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. 14 thru 17\n",
    "2. 18 thru 24\n",
    "3. 25 thru 34\n",
    "4. 35 thru 44\n",
    "5. 45 thru 54\n",
    "6. 55 thru 64\n",
    "7. 65 and Over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_map = {\n",
    "    1: 16,\n",
    "    2: 21,\n",
    "    3: 30,\n",
    "    4: 40,\n",
    "    5: 50,\n",
    "    6: 60,\n",
    "    7: 75\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Grade 8 or less\n",
    "2. Grades 9 to 11\n",
    "3. Graduated high school\n",
    "4. 1 to 3 years of college\n",
    "5. College graduate\n",
    "6. Grad Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_map = {\n",
    "    1: \"Grade 8 or less\",\n",
    "    2: \"Grades 9 to 11\",\n",
    "    3: \"Graduated high school\",\n",
    "    4: \"1 to 3 years of college\",\n",
    "    5: \"College graduate\",\n",
    "    6: \"Grad Study\",\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Professional/Managerial\n",
    "2. Sales Worker\n",
    "3. Factory Worker/Laborer/Driver\n",
    "4. Clerical/Service Worker\n",
    "5. Homemaker\n",
    "6. Student, HS or College\n",
    "7. Military\n",
    "8. Retired\n",
    "9. Unemployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_map = {\n",
    "    1: \"Professional/Managerial\",\n",
    "    2: \"Sales Worker\",\n",
    "    3: \"Factory Worker/Laborer/Driver\",\n",
    "    4: \"Clerical/Service Worker\",\n",
    "    5: \"Homemaker\",\n",
    "    6: \"Student, HS or College\",\n",
    "    7: \"Military\",\n",
    "    8: \"Retired\",\n",
    "    9: \"Unemployed\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Less than one year\n",
    "2. One to three years\n",
    "3. Four to six years\n",
    "4. Seven to ten years\n",
    "5. More than ten years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "living_period_map = {\n",
    "    1: 0,\n",
    "    2: 2,\n",
    "    3: 5,\n",
    "    4: 9,\n",
    "    5: 15\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Not Married\n",
    "2. Yes\n",
    "3. No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_incomes_map = {\n",
    "    1: \"Not Married\",\n",
    "    2: \"Yes\",\n",
    "    3: \"No\"\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. Own\n",
    "2. Rent\n",
    "3. Live with Parents/Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "householder_status_map = {\n",
    "    1: \"Own\",\n",
    "    2: \"Rent\",\n",
    "    3: \"Live with Parents/Family\",\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. House\n",
    "2. Condominium\n",
    "3. Apartment\n",
    "4. Mobile Home\n",
    "5. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_type_map = {\n",
    "    1: \"House\",\n",
    "    2: \"Condominium\",\n",
    "    3: \"Apartment\",\n",
    "    4: \"Mobile Home\",\n",
    "    5: \"Other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. American Indian\n",
    "2. Asian\n",
    "3. Black\n",
    "4. East Indian\n",
    "5. Hispanic\n",
    "6. Pacific Islander\n",
    "7. White\n",
    "8. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnic_map = {\n",
    "    1: \"American Indian\",\n",
    "    2: \"Asian\",\n",
    "    3: \"Black\",\n",
    "    4: \"East Indian\",\n",
    "    5: \"Hispanic\",\n",
    "    6: \"Pacific Islander\",\n",
    "    7: \"White\",\n",
    "    8: \"Other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. English\n",
    "2. Spanish\n",
    "3. Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_map = {\n",
    "    1: \"English\",\n",
    "    2: \"Spanish\",\n",
    "    3: \"Other\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_column(x: Any, mapp: Dict[Any, Any]) -> Any:\n",
    "    if pd.isna(x): \n",
    "        return x\n",
    "    return mapp[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_for_visualisation = {\n",
    "    \"INCOME\": decode_income_map,\n",
    "    \"SEX\": decode_sex_map,\n",
    "    \"MARITAL_STATUS\": decode_marital_status_map,\n",
    "    \"AGE\": age_map,\n",
    "    \"EDUCATION\": education_map,\n",
    "    \"OCCUPATION\": occupation_map,\n",
    "    \"LIVING_PERIOD\": living_period_map,\n",
    "    \"DUAL_INCOMES\": dual_incomes_map,\n",
    "    \"HOUSEHOLDER_STATUS\": householder_status_map,\n",
    "    \"HOME_TYPE\": home_type_map,\n",
    "    \"ETHNIC\": ethnic_map,\n",
    "    \"LANGUAGE\": language_map,\n",
    "}\n",
    "\n",
    "maps_for_models = {\n",
    "    \"INCOME\": decode_income_map,\n",
    "    \"SEX\": decode_sex_map,\n",
    "    \"MARITAL_STATUS\": decode_marital_status_map,\n",
    "    \"AGE\": age_map,\n",
    "    \"OCCUPATION\": occupation_map,\n",
    "    \"LIVING_PERIOD\": living_period_map,\n",
    "    \"DUAL_INCOMES\": dual_incomes_map,\n",
    "    \"HOUSEHOLDER_STATUS\": householder_status_map,\n",
    "    \"HOME_TYPE\": home_type_map,\n",
    "    \"ETHNIC\": ethnic_map,\n",
    "    \"LANGUAGE\": language_map,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in df.columns:\n",
    "#     if column in maps_for_visualisation:\n",
    "#         df[column] = df[column].apply(decode_column, args = (maps_for_visualisation,))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applay_maps(df: pd.DataFrame, maps: Dict[str, Dict[Any, Any]]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column in maps:\n",
    "            df[column] = df[column].apply(decode_column, args = (maps[column],))  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = applay_maps(df, maps_for_models)\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Посмотрим на распределение параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_statistic(df: pd.DataFrame) -> None:\n",
    "    for column in df.columns:\n",
    "        print(column)\n",
    "        counts = df[column].value_counts().sort_index()\n",
    "        \n",
    "        names = counts.index\n",
    "        if column in maps_for_visualisation:\n",
    "            names = [str(decode_column(i, maps_for_visualisation[column])) for i in names]\n",
    "            \n",
    "        counts = counts.values\n",
    "        plt.bar(names, counts)\n",
    "        plt.xticks(rotation=45, ha=\"right\")\n",
    "        plt.show()\n",
    "show_statistic(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1) Имеем достаточно много одиноких покупателей. Можно предлагать товары, которые упрощают ведение хозяйства.\n",
    "    2) Получаем, что женщины чаще ходят в наш супермаркет. Может оказаться так, что в семьях чаще покупками занимаются женщины. Стоит посмотреть соотношение одиноких женщин и одиноких мужчин, если и там баланс будет нарушен, значит есть потенциал развития магазина для одного из полов.\n",
    "    3) Большинство клиентов прожили достаточно долго на одном месте, стоит проверить, являются ли они постоянными покупателями. Если нет - пересмотреть программу лояльности.\n",
    "    4) Достаточно большое кол-во людей живёт с родителями. Если они достаточно взрослые, то можно предлагать им товары для пожилых.\n",
    "    5) Много клиентов живут в домах, стоит проверить достаточно ли товаров для придомовой территории: газонокосилки, поливалки, уличная мебель, грили и т.д.\n",
    "    6) Достаточно много \"Испанцев\", можно сделать предположение, что на самом деле это Мексиканцы. Можно сделать акцент на национальной кухне."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_df = df2[(df2[\"MARITAL_STATUS\"] != \"Married\") & (df2[\"MARITAL_STATUS\"] != \"Living together, not married\")]\n",
    "counts = single_df[\"SEX\"].value_counts().sort_index()\n",
    "print(counts[\"m\"] / counts[\"f\"])\n",
    "counts = df2[\"SEX\"].value_counts().sort_index()\n",
    "print(counts[\"m\"] / counts[\"f\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что соотношение одиноких мужчин/женщин ещё ниже. Если посмотреть соотношение полов в США в 1990 году, то увидим, что соотношение составляет ~0,95. https://www.statista.com/statistics/241495/us-population-by-sex/\n",
    "Наши значения говорят о том, что есть не раскрытый потенциал для одиноких мужчин. Конечно, многое зависит от способа проведения запроса, что может влиять на выводы. Например, если опрос проводился только один день, а одинокие мужчины закупаются реже."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим ещё распределение по доходу на одного человека."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_per_person = df2[\"INCOME\"] / df2[\"PERSONS_COUNT\"]\n",
    "counts = income_per_person.value_counts(bins=20).sort_index()\n",
    "indeces = [str(i.left) + \"-\" + str(i.right) for i in counts.index]\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.bar([str(int(i.left)) + \"-\" + str(int(i.right)) for i in counts.index], counts.values)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует группа клиентов, получающих доход на одного человека, который выше, чем средний доход на одного человека в Сан-Франциско в 1987 (~$23700) https://fred.stlouisfed.org/series/PCPI06075 . Стоит рассмотреть их продуктовую корзину. Можно увеличить кол-во более дорогих товаров лучшего качества, если их нет в этой корзине.\n",
    "При построении модели можно сгенерить фичу на основе кол-ва человек и значении среднего дохода на человека."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr(method=\"kendall\")\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на зависимости признаков, особенно на те, которые коррелируют, чтобы понять какие именно есть зависимости."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"AGE\", hue=\"INCOME\", height=8.27, aspect=11.7/8.27, kind=\"count\", data=df2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"EDUCATION\", hue=\"INCOME\", height=8.27, aspect=11.7/8.27, kind=\"count\", data=df2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"DUAL_INCOMES\", hue=\"INCOME\", height=8.27, aspect=11.7/8.27, kind=\"count\", data=df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Молодые, люди с низким образованием и одинокие чаще всего получают небольшой доход. Что логично."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"HOME_TYPE\", hue=\"MARITAL_STATUS\", height=8.27, aspect=11.7/8.27, kind=\"count\", data=df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Женатые пары чаще всего живут в домах. Не совсем понятно, что это даёт бизнесу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"ETHNIC\", hue=\"EDUCATION\", height=8.27, aspect=11.7/8.27, kind=\"count\", data=df2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Есть ли косяки в данных?\n",
    "    1) Проверим противоречия в вопросах про замужество\n",
    "    2) Посмотрим на домохозяйства, полностью состоящие из несовершеннолетних не студентов (это не обязательно косяк, но подозрительно).\n",
    "    3) Посмотрим на домохозяйства, где было указано, что несовершеннолетних больше, чем всего человек.\n",
    "    4) Домохозяйства, в которых больше говорят на Испанском, но чувак указал, что он не Испанец. (это не обязательно косяк, но подозрительно)\n",
    "    5) Молодые люди на пенсии (это не обязательно косяк, но подозрительно)\n",
    "    6) Выпускники колледжа младше 18 (это не обязательно косяк, но подозрительно)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_data = df2[\n",
    "    ((df2[\"DUAL_INCOMES\"] == \"Not Married\") & (df2[\"MARITAL_STATUS\"] == \"Married\")) | \\\n",
    "    (df2[\"PERSONS_UNDER_18\"] > df[\"PERSONS_COUNT\"]) | \\\n",
    "    ((df2[\"PERSONS_UNDER_18\"] == df2[\"PERSONS_COUNT\"]) & (df2[\"OCCUPATION\"] != \"Student, HS or College\")) | \\\n",
    "    ((df2[\"ETHNIC\"] != \"Hispanic\") & (df2[\"LANGUAGE\"] == \"Spanish\")) | \\\n",
    "    ((df2[\"OCCUPATION\"] == \"Retired\") & (df2[\"AGE\"] < 40)) | \\\n",
    "    ((df2[\"EDUCATION\"] == \"5\") & (df2[\"AGE\"] < 18))\n",
    "]\n",
    "suspicious_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suspicious_data.shape[0] / df2.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого, имеем ~3% подозрительных данных. Можно сказать, что это не очень хороший результат, т.к. мы смогли использовать не самое большое кол-во эвристик для проверки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income.\n",
    "Давайте глянем что будет если мы просто засунем все данные в какую-нибудь модель. Все пропуски заменим на специальное значение. За модель возьмём решающее дерево. Немного запаримся и будем обрабатывать признаки в зависимости от их типа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pd.isnull(df[\"INCOME\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_types = {\n",
    "    \"INCOME\": \"ord\",\n",
    "    \"SEX\": \"bin\",\n",
    "    \"MARITAL_STATUS\": \"cat\",\n",
    "    \"AGE\": \"ord\",\n",
    "    \"EDUCATION\": \"ord\",\n",
    "    \"OCCUPATION\": \"cat\",\n",
    "    \"LIVING_PERIOD\": \"ord\",\n",
    "    \"DUAL_INCOMES\": \"cat\",\n",
    "    \"PERSONS_COUNT\": \"ord\",\n",
    "    \"PERSONS_UNDER_18\": \"ord\",\n",
    "    \"HOUSEHOLDER_STATUS\": \"cat\",\n",
    "    \"HOME_TYPE\": \"cat\",\n",
    "    \"ETHNIC\": \"cat\",\n",
    "    \"LANGUAGE\": \"cat\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_to_features = {}\n",
    "for k, v in features_to_types.items():\n",
    "    if v not in types_to_features:\n",
    "        types_to_features[v] = set()\n",
    "    types_to_features[v].add(k)\n",
    "types_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2 = applay_maps(df, maps_for_models)\n",
    "# for column in df.columns:\n",
    "#     if column in maps_for_models:\n",
    "#         df2[column] = df2[column].apply(decode_column, args = (maps_for_models[column],))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_df(df: pd.DataFrame, features_to_types: Dict[str, str]) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for column in df.columns:\n",
    "        t = features_to_types[column]\n",
    "        if t == \"cat\" or t == \"bin\":\n",
    "            df = pd.concat([df.drop(column, axis=1), pd.get_dummies(df[column], prefix=column + \"_is\")], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = encode_df(df2, features_to_types=features_to_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2[\"INCOME\"].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2.drop(\"INCOME\", axis=1).to_numpy()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(class_weight=\"balanced\")\n",
    "clf = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clf.score(X_train, y_train))\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Что получили?\n",
    "Даже по метрике Accuracy видно, что модель нормально так переобучилась. Попробуем задать либо максимальную глубину дерева, либо минимальное кол-во экземпляров в листах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 120):\n",
    "    clf = DecisionTreeClassifier(min_samples_leaf=i, class_weight=\"balanced\")\n",
    "    clf = clf.fit(X_train, y_train)\n",
    "    print (\"=============== \" + str(i) + \" ===============\")\n",
    "    print(clf.score(X_train, y_train))\n",
    "    print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как-то не впечатляет\n",
    "Хммм... Простым перебором минимального кол-ва экземпляров в листах смогли убрать переобучение и вырвали пару пунктов. Теперь попробуем поработать нормально. Начнём с заполнения пропусков.\n",
    "Самый простой способ: для категориальных признаков взять наиболее частое значение, для числовых - медиану.\n",
    "Конечно, можно попредсказывать пустые поля на основании остальных, но пока не будем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_classifier(df: pd.DataFrame) -> None:    \n",
    "    y = df[\"INCOME\"].to_numpy()\n",
    "    X = df2.drop(\"INCOME\", axis=1).to_numpy()\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "    \n",
    "    \n",
    "    for i in range(1, 120):\n",
    "        clf = DecisionTreeClassifier(min_samples_leaf=i, max_depth=5, class_weight=\"balanced\")\n",
    "        clf = clf.fit(X_train, y_train)\n",
    "        print (\"=============== \" + str(i) + \" ===============\")\n",
    "        print(clf.score(X_train, y_train))\n",
    "        print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "for column in df2.columns:\n",
    "    t = features_to_types[column]\n",
    "    if t == \"cat\" or t == \"bin\":\n",
    "        df2[column] = df2[column].fillna(df2[column].value_counts().index[0])\n",
    "    elif t == \"ord\":\n",
    "        df2[column] = df2[column].fillna(df2[column].median())\n",
    "df2.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = applay_maps(df2, maps_for_models)\n",
    "df2 = encode_df(df2, features_to_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_classifier(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем добавить новых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "for column in df2.columns:\n",
    "    t = features_to_types[column]\n",
    "    if t == \"cat\" or t == \"bin\":\n",
    "        df2[column] = df2[column].fillna(df2[column].value_counts().index[0])\n",
    "    elif t == \"ord\":\n",
    "        df2[column] = df2[column].fillna(df2[column].median())\n",
    "\n",
    "df2[\"PERSONS_OLDER_18\"] = df2[\"PERSONS_COUNT\"] - df2[\"PERSONS_UNDER_18\"]\n",
    "df2[\"MEAN_INCOME\"] = (df2[\"PERSONS_OLDER_18\"] + df2[\"PERSONS_UNDER_18\"]*0.05)*20000\n",
    "df2[\"SMTH1\"] = (df2[\"PERSONS_OLDER_18\"] + df2[\"PERSONS_UNDER_18\"]*0.2)*20000*df2[\"AGE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_features_to_types = deepcopy(features_to_types)\n",
    "advanced_features_to_types[\"PERSONS_OLDER_18\"] = \"ord\"\n",
    "advanced_features_to_types[\"MEAN_INCOME\"] = \"ord\"\n",
    "advanced_features_to_types[\"SMTH1\"] = \"ord\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = applay_maps(df2, maps_for_models)\n",
    "df2 = encode_df(df2, advanced_features_to_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_classifier(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([(\"classifier\", XGBClassifier())])\n",
    "\n",
    "# pipe.fit(X_train, y_train) \n",
    "\n",
    "params = {\n",
    " \"classifier__max_depth\": list(range(1, 10)),\n",
    " \"classifier__n_jobs\": [4],\n",
    " \"classifier__n_estimators\": [10, 20, 50, 100]\n",
    "}\n",
    "gs = GridSearchCV(estimator=pipeline, param_grid=params , scoring=\"f1_micro\")\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.best_params_, gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = gs.best_estimator_\n",
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
